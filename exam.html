<hmtl>
    <head>

    </head>
    <body>
        <h1> Final excam</h1>
        <br>
        <p>This project will use some trainingdata. The goal is to predict the manner in wich they did there excercises. Since this is a classification problem, the following tree algorithms were chosen for this purpose.</p>
        <ul>
            <li>SVMLinear</li>
            <li>Random Forest</li>
            <li>rpart</li>
            <li>GBM</li>
        </ul>
        <h2>Step 1: Download the Data as CSV file</h2>
        <h2>Step 2: Load the required packages</h2>
        <p>
            library(lattice)<br>
            library(caret)<br>
            library(kernlab)<br>
            library(rattle)<br>
        </p>    
        <h2>Step 3: Read the data and set seed</h2>
        <p>First I uploaded the csvs into the sandbox. Next, I read in the CSV files using the read.csv() command. Last I set the seed to 12345 for the purpose of repeatability.</p>
        <p>training <- read.csv("~/pml-training.csv")<br>
        testing <- read.csv("~/pml-testing.csv")<br>
        set.seed(12345)<br></p>
        <h2>Step 4: Clean the data</h2>
        <p>First, the proportion of NA lines was reduced. Now the variance was increased with nearZeroVar().</p>
        <p>
            training <- training[,colMeans(is.na(training)) < 0.9]<br>
            training <- training[,-c(1:7)] <br>

            nvz <- nearZeroVar(training)<br>
            training <- training[,-nvz]<br></p>
        <h2>Step 5: Building a training and testing dataset</h2>
        <p>With createDataPartition() the data set was divided into a training set and a test set where 70% of the data is used for training. Now the data was loaded into separate array. Last the validation() method is initialized.</p>
        <p>
            inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)<br>
            train <- training[inTrain, ]<br>
            test  <- training[-inTrain, ]<br>
            dim(train)<br>
            dim(test)<br>

            validation <- trainControl(method="cv", number=3, verboseIter=F)<br>

        </p>
        <h2>Step 6: Train and test the SVMLinear model</h2>
        <p>To train and test the model I use the code below.</p>
        <p>
            modelFit1 <- train(classe~., data=train, method="svmLinear", trControl = validation, tuneLength = 5, verbose = F)<br>
            pred_model1 <- predict(modelFit1, test)<br>
            cm_mod1 <- confusionMatrix(pred_model1, factor(test$classe))<br>
            cm_mod1<br>
        </p>
        <h2>Step 7: Train and test the Random Forest model</h2>
        <p>To train and test the model I use the code below.</p>
        <p>
            modelFit2 <- train(classe~., data=train, method="rf", trControl = validation, tuneLength = 5)<br>
            pred_model2 <- predict(modelFit2, test)<br>
            cm_mod2<- confusionMatrix(pred_model2, factor(test$classe))<br>
            cm_mod2<br>
        </p>
        <h2>Step 8: Train and test the rpart model</h2>
        <p>To train and test the model I use the code below.</p>
        <p>
            modelFit3 <- train(classe~., data=train, method="rpart", trControl = validation, tuneLength = 5)<br>
            pred_model3 <- predict(modelFit3, test)<br>
            cm_mod3 <- confusionMatrix(pred_model3, factor(test$classe))<br>
            cm_mod3<br>
        </p>
        <h2>Step 9: Train and test the GBM model</h2>
        <p>To train and test the model I use the code below.</p>
        <p>
            modelFit4 <- train(classe~., data=train, method="gbm", trControl = validation, tuneLength = 5, verbose = F)<br>
            pred_model4 <- predict(modelFit4, test)<br>
            cm_mod4 <- confusionMatrix(pred_model4, factor(test$classe))<br>
            cm_mod4<br>
        </p>
        <h2>Step 10: Predict</h2>
        <p>Since the Random Forest model and the GBM model have nearly identical accuracy, both models are tested separately. Perhaps the small deviation provides a different result.</p>
        <h3>1. Start with the Random Forest model.</h3>
        <p>To predict with these model I use the predict() method.</p>
        <p>pred_randomForest <- predict(modelFit2, testing)<br>
            print(pred_randomForest)<br></p>
        <p>The predict values are:</p>
        <p>[1] B A B A A E D B A A B C B A E E A B B B<br>
            Levels: A B C D E</p>
        <h3>2. Predicton with th GBM model</h3>
        <p>To predict with these model I use the predict() method.</p>
        <p>pred_gbm <- predict(modelFit4,testing)<br>
            print(pred_gbm)<br></p>
        <p>The predicted values are:</p>
        <p>[1] B A B A A E D B A A B C B A E E A B B B<br>
            Levels: A B C D E</p>
        <h3>3. Lets check if the results are identical</h3>
        <p>To check these I use a simple boolean check in the print() method.</p>
        <p>print(pred_randomForest == pred_gbm)<br></p>
        <p>The result is:</p>
        <p>[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE<br>
            [10] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE<br>
            [19] TRUE TRUE</p>
        <p>As you can see the results are identical and therefore it doesn't matter which model you choose.</p>
    </body>
</hmtl>